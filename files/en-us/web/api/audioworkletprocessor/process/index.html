---
title: AudioWorkletProcessor.process
slug: Web/API/AudioWorkletProcessor/process
tags:
- API
- Audio
- AudioWorkletNode
- AudioWorkletProcessor
- Experimental
- Method
- Process
- Reference
- Web Audio API
browser-compat: api.AudioWorkletProcessor.process
---
<p>{{APIRef("Web Audio API")}}</p>

<p class="summary"><span class="seoSummary">The <strong><code>process()</code></strong>
    method of an {{domxref("AudioWorkletProcessor")}}-derived class implements the audio
    processing algorithm for the audio processor worklet.</span> Although the method is
  not a part of the {{domxref("AudioWorkletProcessor")}} interface, any implementation
  of <code>AudioWorkletProcessor</code> must provide a <code>process()</code> method.</p>

<p>The method is called synchronously from the audio rendering thread, once for each block
  of audio (also known as a rendering quantum) being directed through the processor's
  corresponding {{domxref("AudioWorkletNode")}}. In other words, every time a new block of
  audio is ready for your processor to manipulate, your <code>process()</code> function is
  invoked to do so.</p>

<div class="notecard note">
  <p><strong>Important:</strong> Currently, audio data blocks are always 128 frames
    long—that is, they contain 128 32-bit floating-point samples for each of the inputs'
    channels. However, plans are already in place to revise the specification to allow the
    size of the audio blocks to be changed depending on circumstances (for example, if the
    audio hardware or CPU utilization is more efficient with larger block sizes).
    Therefore, you <em>must always check the size of the sample array</em> rather than
    assuming a particular size.</p>

  <p>This size may even be allowed to change over time, so you mustn't look at just the
    first block and assume the sample buffers will always be the same size.</p>
</div>

<h2 id="Syntax">Syntax</h2>

<pre class="brush: js">var <em>isActivelyProcessing</em> = <em>audioWorkletProcessor</em>.process(<em>inputs</em>, <em>outputs</em>, <em>parameters</em>);
</pre>

<h3 id="Parameters">Parameters</h3>

<dl>
  <dt><code>inputs</code></dt>
  <dd>
    <p>An array of <em>inputs</em> connected to the node, each item of which is, in turn,
      an array of <em>channels</em>. Each <em>channel</em> is a {{jsxref("Float32Array")}}
      containing 128 samples. For example, <code>inputs[n][m][i]</code> will access
      <em>n</em>-th input, <em>m</em>-th channel of that input, and <em>i</em>-th sample
      of that channel.</p>

    <p>Each sample value is in range of <code>[-1 .. 1]</code>.</p>

    <p>The number of <em>inputs</em> and thus the length of that array is fixed at the
      construction of the node (see {{domxref("AudioWorkletNode")}}). If there is
      no active node connected to the <em>n</em>-th input of the node,
      <code>inputs[n]</code> will be an empty array (zero input channels available).</p>

    <p>The number of <em>channels</em> in each input may vary, depending on
      {{domxref("AudioNode.channelCount", "channelCount")}} and
      {{domxref("AudioNode.channelCountMode", "channelCountMode")}} properties.</p>
  </dd>
  <dt><code>outputs</code></dt>
  <dd>An array of <em>outputs</em> that is similar to the <code>inputs</code> parameter in
    structure. It is intended to be filled during the execution of the
    <code>process()</code> method. Each of the output channels is filled with zeros by
    default — the processor will output silence unless the output arrays are modified.
  </dd>
  <dt><code>parameters</code></dt>
  <dd>
    <p>An object containing string keys and {{jsxref("Float32Array")}} values. For each
      custom {{domxref("AudioParam")}} defined using the
      {{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}}
      getter, the key in the object is a <code>name</code> of that
      {{domxref("AudioParam")}}, and the value is a {{jsxref("Float32Array")}}. The values
      of the array are calculated by taking scheduled automation events into
      consideration.</p>

    <p>If the automation rate of the parameter is
      <code><a href="/en-US/docs/Web/API/AudioParam#a-rate">"a-rate"</a></code>, the array
      will contain 128 values — one for each frame in the current audio block. If there's
      no automation happening during the time represented by the current block, the array
      may contain a single value that is constant for the entire block, instead of 128
      identical values.</p>

    <p>If the automation rate is
      <code><a href="/en-US/docs/Web/API/AudioParam#k-rate">"k-rate"</a></code>, the array
      will contain a single value, which is to be used for each of 128 frames.</p>
  </dd>
</dl>

<h3 id="Return_value">Return value</h3>

<p>A Boolean value indicating whether or not to force the {{domxref("AudioWorkletNode")}}
  to remain active even if the {{Glossary("user agent", "user agent's")}} internal logic
  would otherwise decide that it's safe to shut down the node.</p>

<p>The returned value lets your processor have influence over the lifetime policy of
  the {{domxref("AudioWorkletProcessor")}} and the node that owns it. If the combination
  of the return value and the state of the node causes the browser to decide to stop the
  node, <code>process()</code> will not be called again.</p>

<p>Returning <code>true</code> forces the Web Audio API to keep the node alive,
  while returning <code>false</code> allows the browser to terminate the node if it is
  neither generating new audio data nor receiving data through its inputs that it is
  processing.</p>

<p>The 3 most common types of audio node are:</p>

<ol>
  <li>A source of output. An {{domxref("AudioWorkletProcessor")}} implementing such a node
    should return <code>true</code> from the <code>process</code> method as long as it
    produces an output. The method should return <code>false</code> as soon as it's known
    that it will no longer produce an output. For example, take the
    {{domxref("AudioBufferSourceNode")}} — the processor behind such a node should return
    <code>true</code> from the <code>process</code> method while the buffer is playing,
    and start returning <code>false</code> when the buffer playing has ended (there's no
    way to call <code>play</code> on the same {{domxref("AudioBufferSourceNode")}} again).
  </li>
  <li>A node that transforms its input. A processor implementing such a node should return
    <code>false</code> from the <code>process</code> method to allow the presence of
    active input nodes and references to the node to determine whether it can be
    garbage-collected. An example of a node with this behavior is the
    {{domxref("GainNode")}}. As soon as there are no inputs connected and references
    retained, gain can no longer be applied to anything, so it can be safely
    garbage-collected.</li>
  <li>A node that transforms its input, but has a so-called <em>tail-time</em> — this
    means that it will produce an output for some time even after its inputs are
    disconnected or are inactive (producing zero-channels). A processor implementing such
    a node should return <code>true</code> from the <code>process</code> method for the
    period of the <em>tail-time</em>, beginning as soon as inputs are found that contain
    zero-channels. An example of such a node is the {{domxref("DelayNode")}} — it has a
    <em>tail-time</em> equal to its {{domxref("DelayNode.delayTime", "delayTime")}}
    property.</li>
</ol>

<p class="note"><strong>Note</strong>: An absence of the <code>return</code> statement
  means that the method returns <code>undefined</code>, and as this is a falsy value, it
  is like returning <code>false</code>. Omitting an explicit <code>return</code> statement
  may cause hard-to-detect problems for your nodes.</p>

<h3 id="Exceptions">Exceptions</h3>

<p>As the <code>process()</code> method is implemented by the user, it can throw anything.
  If an uncaught error is thrown, the node will emit an
  {{domxref("AudioWorkletNode.onprocessorerror", "onprocessorerror")}} event and will
  output silence for the rest of its lifetime.</p>

<h2 id="Examples">Examples</h2>

<p>In this example we create an <code>AudioWorkletProcessor</code> that outputs white
  noise to its first output. The gain can be controlled by the <code>customGain</code>
  parameter.</p>

<pre class="brush: js">class WhiteNoiseProcessor extends AudioWorkletProcessor {
  process (inputs, outputs, parameters) {
    // take the first output
    const output = outputs[0]
    // fill each channel with random values multiplied by gain
    output.forEach(channel =&gt; {
      for (let i = 0; i &lt; channel.length; i++) {
        // generate random value for each sample
        // Math.random range is [0; 1); we need [-1; 1]
        // this won't include exact 1 but is fine for now for simplicity
        channel[i] = (Math.random() * 2 - 1) *
          // the array can contain 1 or 128 values
          // depending on if the automation is present
          // and if the automation rate is k-rate or a-rate
          (parameters['customGain'].length &gt; 1
            ? parameters['customGain'][i]
            : parameters['customGain'][0])
      }
    })
    // as this is a source node which generates its own output,
    // we return true so it won't accidentally get garbage-collected
    // if we don't have any references to it in the main thread
    return true
  }
  // define the customGain parameter used in process method
  static get parameterDescriptors () {
    return [{
      name: 'customGain',
      defaultValue: 1,
      minValue: 0,
      maxValue: 1,
      automationRate: 'a-rate'
    }]
  }
}
</pre>

<h2 id="Specifications">Specifications</h2>

{{Specifications}}

<h2 id="Browser_compatibility">Browser compatibility</h2>

<p>{{Compat}}</p>

<h2 id="See_also">See also</h2>

<ul>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio
      API</a></li>
</ul>
