---
title: XRWebGLLayer.getNativeFramebufferScaleFactor() static method
slug: Web/API/XRWebGLLayer/getNativeFramebufferScaleFactor
tags:
  - API
  - AR
  - Effective
  - Factor
  - Reality
  - Reference
  - Scaling
  - Static
  - Static Method
  - VR
  - Virtual
  - WebXR
  - WebXR API
  - WebXR Device API
  - XR
  - XRWebGLLayer
  - augmented
  - framebuffer
  - getNativeFramebufferScaleFactor
  - native
  - resolution
browser-compat: api.XRWebGLLayer.getNativeFramebufferScaleFactor
---
<p>{{securecontext_header}}{{APIRef("WebXR Device API")}}</p>

<p><span class="seoSummary">The static method
    <code><strong>XRWebGLLayer.getNativeFramebufferScaleFactor()</strong></code> returns a
    floating-point scaling factor by which one can multiply the specified
    {{domxref("XRSession")}}'s resolution to get the native resolution of the WebXR
    device's frame buffer.</span></p>

<p>This information can be used when creating a new <code>XRWebGLLayer</code> to configure
  the {{domxref("XRWebGLLayerInit")}} property
  {{domxref("XRWebGLLayerInit.framebufferScaleFactor", "framebufferScaleFactor")}} in the
  options specified when calling the <code>XRWebGLLayer()</code> constructor. See the
  {{anch("Usage notes")}} and {{anch("Examples")}} for details.</p>

<p>If the scaling factor is 1.0, then the frame buffer pixels and the native display
  pixels are the same size. If the scaling factor is greater than zero, then the frame
  buffer is smaller than the diplay's native dimensions, resulting in the output being
  up-scaled for display to the screen after rendering into the frame buffer. If the
  scaling factor is less than zero, the frame buffer is <em>larger</em> than the native
  resolution of the display, resulting in the frame buffer's contents being scaled down
  for display to the XR device. This can happen for display environments which use
  superscaling or anti-aliasing techniques to improve perceived image quality.</p>

<h2 id="Syntax">Syntax</h2>

<pre
  class="brush: js">let <em>nativeScaling</em> = XRWebGLLayer.getNativeFramebufferScaleFactor(<em>session</em>);</pre>

<h3 id="Parameters">Parameters</h3>

<dl>
  <dt><code>session</code></dt>
  <dd>The {{domxref("XRSession")}} for which to return the native framebuffer scaling
    factor.</dd>
</dl>

<h3 id="Return_value">Return value</h3>

<p>A floating-point value which, when multiplied by the {{domxref("XRSession")}}'s
  recommended framebuffer dimensions, results in the XR device's native frame buffer
  resolution. If the session has ended, this function returns 0.0.</p>

<h2 id="Usage_notes">Usage notes</h2>

<p>The scaling factor returned by this function will be 1.0 if the native resolution of
  the XR device and the resolution of the XR device match. In any case, multiplying the
  recommended resolution as identified by the <code>XRSession</code> by this value will
  result in the actual native resolution of the XR hardware.</p>

<p>The recommended WebGL frame buffer resolution is the best possible estimate of the
  resolution necessary to contain all of fthe {{domxref("XRView")}}s needed by the device
  while at the same time providing typical applications an acceptable balance of image
  quality and performance.</p>

<p>For example, consider a device which uses a 2560x1440 pixel frame buffer (which is used
  to render two views, for the left and right eyes, side by side each at a resolution of
  1280x1440 pixels). Consider a frame buffer which at full size looks like this:</p>

<p><img alt="Diagram showing how a framebuffer is divided between two eyes' viewpoints"
    src="twoviewsoneframebuffer.svg"></p>

<p>If, on this device, it's determined that due to GPU limitations the browser needs to
  reduce image quality in order to improve performance to an acceptable level, it might
  choose to halve the resolution. In this case, the value returned by
  <code>XRWebGLLayer.getNativeFramebufferScaleFactor()</code> will be 2.0. This method of
  dividing the frame buffer between views is shown in the following diagram.</p>

<p><img alt="Diagram showing frame buffer as scalled to half resolution"
    src="twoviewsoneframe-scaledby2.svg"></p>

<p>Now the width and height of the frame buffer are 50% what they were before, resulting
  in a total frame buffer size of 1280 by 720 pixels, with each eye's half of the buffer
  being 640x720 pixels. Now we can see the coordinates of each of the viewports
  representing these two views:</p>

<p><img alt=""
    src="twoviewsviewportcoords-scaledby2.svg"></p>

<p>Since each eye gets half of the frame buffer, the result is that the left eye gets a
  640x720 portion of the buffer with the viewport's <code>x</code> and <code>y</code> at
  0, the width at 640, and the height set to 720. The right eye gets the other half of the
  frame buffer, with its viewport's <code>x</code> set at 639.</p>

<p>While <a
    href="/en-US/docs/Web/API/XRWebGLLayer#rendering_every_view_in_a_frame">rendering a
    frame for this scene</a>, we get the viewport for the view and apply it to WebGL, then
  render the scene. This ensures that the scene we render will not only match the
  viewpoint we need to express (which is defined by the position and orientation data in
  the pose), but that the rendered output will be constrained within the correct portion
  of the frame buffer for the eye we're drawing, regardless of any scaling that is being
  performed.</p>

<h2 id="Examples">Examples</h2>

<p>In this example, we request a frame buffer at the device's native resolution,
  regardless of any performance concerns:</p>

<pre class="brush: js">function requestNativeScaleWebGLLayer(gl, xrSession) {
  return gl.makeXRCompatible().then(() =&gt; {
    let scaleFactor = XRWebGLLayer.getNativeFramebufferScaleFactor(xrSession);
    let glLayer = new XRWebGLLayer(xrSession, gl, {
                    framebufferScaleFactor: scaleFactor
    });
    xrSession.updateRenderState({ baseLayer: glLayer });
  });
};
</pre>

<p>This starts by calling the <a href="/en-US/docs/Web/API/WebGLRenderingContext">WebGL
    rendering context</a> function {{domxref("WebGLRenderingContext.makeXRCompatible",
  "makeXRCompatible()")}}. When the returned {{jsxref("promise")}} resolves, we proceed by
  calling <code>XRWebGLLayer</code>'s <code>getNativeFramebufferScaleFactor()</code>
  static function to get the scale factor needed to reach the native resolution, and we
  then pass that into the {{domxref("XRWebGLLayer.XRWebGLLayer", "WebGLLayer()")}}
  constructor as the value of the {{domxref("XRWebGLLayerInit.framebufferScaleFactor",
  "framebufferScaleFactor")}} property in its <code>layerInit</code> dictionary, which is
  an {{domxref("XRWebGLLayerInit")}} object.</p>

<p>That gets us a new {{domxref("XRWebGLLayer")}} object representing a rendering surface
  we can use for the {{domxref("XRSession")}}; we set it as the rendering surface for
  <code>xrSession</code> by calling its {{domxref("XRSession.updateRenderState",
  "updateRenderState()")}} method, passing the new <code>glLayer</code> in using the
  {{domxref("XRRenderState")}} dictionary's {{domxref("XRRenderState.baseLayer")}}
  property. The result is a rendering context that looks like the diagram below:</p>

<p><img alt="" src="twoviewsviewportcoords.svg"></p>

<p>Each time the {{domxref("XRViewerPose")}}'s {{domxref("XRViewerPose.views", "views")}}
  are iterated over for rendering, the rendering loop obtains an {{domxref("XRView")}} for
  the left eye which has its top-left corner at (0, 0) with its width and height being
  1280x1440 pixels. The right eye it obtains has its top-left corner at 1280, 0 with the
  same width and height: 1280x1440.</p>

<h2 id="Specifications">Specifications</h2>

{{Specifications}}

<h2 id="Browser_compatibility">Browser compatibility</h2>

<p>{{Compat}}</p>

<h2 id="See_also">See also</h2>

<ul>
  <li><a href="/en-US/docs/Web/API/WebXR_Device_API">WebXR Device API</a></li>
  <li><a href="/en-US/docs/Web/API/WebXR_Device_API/Performance">WebXR performance
      guide</a></li>
</ul>
