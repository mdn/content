---
title: AudioContext.getOutputTimestamp()
slug: Web/API/AudioContext/getOutputTimestamp
tags:
  - API
  - Audio
  - AudioContext
  - Method
  - Reference
  - Web Audio API
  - getOutputTimestamp
  - sound
browser-compat: api.AudioContext.getOutputTimestamp
---
<p>{{APIRef("Web Audio API")}}</p>

<p class="summary"><span class="seoSummary">The
    <strong><code>getOutputTimestamp()</code></strong> property of the
    {{domxref("AudioContext")}} interface returns a new <code>AudioTimestamp</code> object
    containing two audio timestamp values relating to the current audio context.</span>
</p>

<p>The two values are as follows:</p>

<ul>
  <li><code>AudioTimestamp.contextTime</code>: The time of the sample frame currently
    being rendered by the audio output device (i.e., output audio stream position), in the
    same units and origin as the context's {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}.
    Basically, this is the time after the audio context was first created.</li>
  <li><code>AudioTimestamp.performanceTime</code>: An estimation of the moment when the
    sample frame corresponding to the stored <code>contextTime</code> value was rendered
    by the audio output device, in the same units and origin as
    {{domxref("performance.now()")}}. This is the time after the document containing the
    audio context was first rendered.</li>
</ul>

<h2 id="Syntax">Syntax</h2>

<pre
  class="brush: js">var timestamp = context.getOutputTimestamp()</pre>

<h3 id="Parameters">Parameters</h3>

<p>None.</p>

<h3 id="Returns">Returns</h3>

<p>An <code>AudioTimestamp</code> object, which has the following properties.</p>

<ul>
  <li><code>contextTime</code>: A point in the time coordinate system of the
    {{domxref("BaseAudioContext/currentTime","currentTime")}} for the
    <code>BaseAudioContext</code>; the time after the audio context was first created.
  </li>
  <li><code>performanceTime</code>: A point in the time coordinate system of a
    <code>Performance</code> interface; the time after the document containing the audio
    context was first rendered</li>
</ul>

<h2 id="Examples">Examples</h2>

<p>In the following code we start to play an audio file after a play button is clicked,
  and start off a <code>requestAnimationFrame</code> loop running, which constantly
  outputs the <code>contextTime</code> and <code>performanceTime</code>.</p>

<p>You can see full code of this <a
    href="https://github.com/mdn/webaudio-examples/blob/master/output-timestamp/index.html">example
    at output-timestamp</a> (<a
    href="https://mdn.github.io/webaudio-examples/output-timestamp/">see it live
    also</a>).</p>

<pre class="brush: js">play.addEventListener('click', () =&gt; {
  if(!audioCtx) {
    audioCtx = new window.AudioContext();
  }

  getData();
  source.start(0);
  play.setAttribute('disabled', 'disabled');

  rAF = requestAnimationFrame(outputTimestamps);
});

stop.addEventListener('click', () =&gt; {
  source.stop(0);
  play.removeAttribute('disabled');
  cancelAnimationFrame(rAF);
});

// function to output timestamps

function outputTimestamps() {
  let ts = audioCtx.getOutputTimestamp()
  console.log('Context time: ' + ts.contextTime + ' | Performance time: ' + ts.performanceTime);
  rAF = requestAnimationFrame(outputTimestamps);
}</pre>

<h2 id="Specifications">Specifications</h2>

{{Specifications}}

<h2 id="Browser_compatibility">Browser compatibility</h2>

<p>{{Compat}}</p>
