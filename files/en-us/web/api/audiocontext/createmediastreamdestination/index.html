---
title: AudioContext.createMediaStreamDestination()
slug: Web/API/AudioContext/createMediaStreamDestination
tags:
  - API
  - AudioContext
  - Method
  - Reference
  - Web Audio API
  - createMediaStreamDestination
browser-compat: api.AudioContext.createMediaStreamDestination
---
<p>{{ APIRef("Web Audio API") }}</p>

<div>
<p>The <code>createMediaStreamDestination()</code> method of the {{ domxref("AudioContext") }} Interface is used to create a new {{domxref("MediaStreamAudioDestinationNode")}} object associated with a <a href="/en-US/docs/Web/API/WebRTC_API">WebRTC</a> {{domxref("MediaStream")}} representing an audio stream, which may be stored in a local file or sent to another computer.</p>
</div>

<p>The {{domxref("MediaStream")}} is created when the node is created and is accessible via the {{domxref("MediaStreamAudioDestinationNode")}}'s <code>stream</code> attribute. This stream can be used in a similar way as a <code>MediaStream</code> obtained via {{domxref("navigator.getUserMedia") }} — it can, for example, be sent to a remote peer using the <code>RTCPeerConnection</code> <code>addStream()</code> method.</p>

<p>For more details about media stream destination nodes, check out the {{domxref("MediaStreamAudioDestinationNode")}} reference page.</p>

<h2 id="Syntax">Syntax</h2>

<pre class="brush: js">var audioCtx = new AudioContext();
var destination = audioCtx.createMediaStreamDestination();</pre>

<h3 id="Returns">Returns</h3>

<p>A {{domxref("MediaStreamAudioDestinationNode")}}.</p>

<h2 id="Examples">Examples</h2>

<p>In the following simple example, we create a {{domxref("MediaStreamAudioDestinationNode")}}, an {{ domxref("OscillatorNode") }} and a {{ domxref("MediaRecorder") }} (the example will therefore only work in Firefox and Chrome at this time.) The <code>MediaRecorder</code> is set up to record information from the <code>MediaStreamDestinationNode</code>.</p>

<p>When the button is clicked, the oscillator starts, and the <code>MediaRecorder</code> is started. When the button is stopped, the oscillator and<code> MediaRecorder</code> both stop. Stopping the <code>MediaRecorder</code> causes the <code>dataavailable</code> event to fire, and the event data is pushed into the <code>chunks</code> array. After that, the <code>stop</code> event fires, a new <code>blob</code> is made of type opus — which contains the data in the <code>chunks</code> array, and a new window (tab) is then opened that points to a URL created from the blob.</p>

<p>From here, you can play and save the opus file.</p>

<pre class="brush: html">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;createMediaStreamDestination() demo&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;createMediaStreamDestination() demo&lt;/h1&gt;

    &lt;p&gt;Encoding a pure sine wave to an Opus file &lt;/p&gt;
    &lt;button&gt;Make sine wave&lt;/button&gt;
    &lt;audio controls&gt;&lt;/audio&gt;
    &lt;script&gt;
     var b = document.querySelector("button");
     var clicked = false;
     var chunks = [];
     var ac = new AudioContext();
     var osc = ac.createOscillator();
     var dest = ac.createMediaStreamDestination();
     var mediaRecorder = new MediaRecorder(dest.stream);
     osc.connect(dest);

     b.addEventListener("click", function(e) {
       if (!clicked) {
           mediaRecorder.start();
           osc.start(0);
           e.target.textContent = "Stop recording";
           clicked = true;
         } else {
           mediaRecorder.stop();
           osc.stop(0);
           e.target.disabled = true;
         }
     });

     mediaRecorder.ondataavailable = function(evt) {
       // push each chunk (blobs) in an array
       chunks.push(evt.data);
     };

     mediaRecorder.onstop = function(evt) {
       // Make blob out of our blobs, and open it.
       var blob = new Blob(chunks, { 'type' : 'audio/ogg; codecs=opus' });
       document.querySelector("audio").src = URL.createObjectURL(blob);
     };
    &lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>

<div class="note">
<p><strong>Note</strong>: You can <a href="https://mdn.github.io/webaudio-examples/create-media-stream-destination/index.html">view this example live</a>, or <a href="https://github.com/mdn/webaudio-examples/blob/master/create-media-stream-destination/index.html">study the source code</a>, on Github.</p>
</div>

<h2 id="Specifications">Specifications</h2>

{{Specifications}}

<h2 id="Browser_compatibility">Browser compatibility</h2>

<p>{{Compat}}</p>

<h2 id="See_also">See also</h2>

<ul>
 <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
</ul>
