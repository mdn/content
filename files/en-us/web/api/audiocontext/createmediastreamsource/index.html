---
title: AudioContext.createMediaStreamSource()
slug: Web/API/AudioContext/createMediaStreamSource
tags:
  - API
  - Audio
  - AudioContext
  - AudioNode
  - Media
  - MediaStream
  - MediaStreamTrack
  - Method
  - Reference
  - Web
  - Web Audio
  - Web Audio API
  - createMediastreamSource
browser-compat: api.AudioContext.createMediaStreamSource
---
<p>{{ APIRef("Web Audio API") }}</p>

<p>The <code>createMediaStreamSource()</code> method of the {{ domxref("AudioContext") }}
  Interface is used to create a new {{ domxref("MediaStreamAudioSourceNode") }}
  object, given a media stream (say, from a {{ domxref("MediaDevices.getUserMedia") }}
  instance), the audio from which can then be played and manipulated.</p>

<p>For more details about media stream audio source nodes, check out the {{
    domxref("MediaStreamAudioSourceNode") }} reference page.</p>

<h2 id="Syntax">Syntax</h2>

<pre
    class="brush: js"><em>audioSourceNode</em> = <em>audioContext</em>.createMediaStreamSource(<em>stream</em>);</pre>

<h3 id="Parameters">Parameters</h3>

<dl>
    <dt><code>stream</code></dt>
    <dd>A {{domxref("MediaStream")}} to serve as an audio source to be fed into an audio
        processing graph for use and manipulation.</dd>
</dl>

<h3 id="Return_value">Return value</h3>

<p>A new {{domxref("MediaStreamAudioSourceNode")}} object representing the audio node
    whose media is obtained from the specified source stream.</p>

<h2 id="Example">Example</h2>

<p>In this example, we grab a media (audio + video) stream from {{
    domxref("navigator.getUserMedia") }}, feed the media into a {{ htmlelement("video") }}
    element to play then mute the audio, but then also feed the audio into a {{
    domxref("MediaStreamAudioSourceNode") }}. Next, we feed this source audio into a low
    pass {{ domxref("BiquadFilterNode") }} (which effectively serves as a bass booster),
    then a {{domxref("AudioDestinationNode") }}.</p>

<p>The range slider below the {{ htmlelement("video") }} element controls the amount of
    gain given to the lowpass filter â€” increase the value of the slider to make the audio
    sound more bass heavy!</p>

<div class="note">
    <p><strong>Note</strong>: You can see this <a
            href="https://mdn.github.io/webaudio-examples/stream-source-buffer/">example
            running live</a>, or <a
            href="https://github.com/mdn/webaudio-examples/tree/master/stream-source-buffer">view
            the source</a>.</p>
</div>

<pre class="brush: js;highlight[23]">var pre = document.querySelector('pre');
var video = document.querySelector('video');
var myScript = document.querySelector('script');
var range = document.querySelector('input');

// getUserMedia block - grab stream
// put it into a MediaStreamAudioSourceNode
// also output the visuals into a video element

if (navigator.mediaDevices) {
    console.log('getUserMedia supported.');
    navigator.mediaDevices.getUserMedia ({audio: true, video: true})
    .then(function(stream) {
        video.srcObject = stream;
        video.onloadedmetadata = function(e) {
            video.play();
            video.muted = true;
        };

        // Create a MediaStreamAudioSourceNode
        // Feed the HTMLMediaElement into it
        var audioCtx = new AudioContext();
        var source = audioCtx.createMediaStreamSource(stream);

        // Create a biquadfilter
        var biquadFilter = audioCtx.createBiquadFilter();
        biquadFilter.type = "lowshelf";
        biquadFilter.frequency.value = 1000;
        biquadFilter.gain.value = range.value;

        // connect the AudioBufferSourceNode to the gainNode
        // and the gainNode to the destination, so we can play the
        // music and adjust the volume using the mouse cursor
        source.connect(biquadFilter);
        biquadFilter.connect(audioCtx.destination);

        // Get new mouse pointer coordinates when mouse is moved
        // then set new gain value

        range.oninput = function() {
            biquadFilter.gain.value = range.value;
        }
    })
    .catch(function(err) {
        console.log('The following gUM error occurred: ' + err);
    });
} else {
   console.log('getUserMedia not supported on your browser!');
}

// dump script to pre element

pre.innerHTML = myScript.innerHTML;</pre>

<div class="note">
    <p><strong>Note</strong>: As a consequence of calling
        <code>createMediaStreamSource()</code>, audio playback from the media stream will
        be re-routed into the processing graph of the {{domxref("AudioContext")}}. So
        playing/pausing the stream can still be done through the media element API and the
        player controls.</p>
</div>

<h2 id="Specifications">Specifications</h2>

{{Specifications}}

<h2 id="Browser_compatibility">Browser compatibility</h2>

<p>{{Compat}}</p>

<h2 id="See_also">See also</h2>

<ul>
    <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio
            API</a></li>
</ul>
