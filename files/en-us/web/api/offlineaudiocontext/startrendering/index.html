---
title: OfflineAudioContext.startRendering()
slug: Web/API/OfflineAudioContext/startRendering
tags:
  - API
  - Method
  - OfflineAudioContext
  - Reference
  - Web Audio API
  - startRendering
browser-compat: api.OfflineAudioContext.startRendering
---
<p>{{ APIRef("Web Audio API") }}</p>

<p>The <code>startRendering()</code> method of the {{ domxref("OfflineAudioContext") }}
  Interface starts rendering the audio graph, taking into account the current connections
  and the current scheduled changes.</p>

<p>The {{event("complete")}} event (of type {{domxref("OfflineAudioCompletionEvent")}}) is
  raised when the rendering is finished, containing the resulting
  {{domxref("AudioBuffer")}} in its <code>renderedBuffer</code> property.</p>

<div>
  <p>Browsers currently support two versions of the <code>startRendering()</code> method â€”
    an older event-based version and a newer promise-based version. The former will
    eventually be removed, but currently both mechanisms are provided for legacy reasons.
  </p>
</div>

<h2 id="Syntax">Syntax</h2>

<p>Event-based version:</p>

<pre class="brush: js">offlineAudioCtx.startRendering();
offlineAudioCtx.oncomplete = function(e) {
  // e.renderedBuffer contains the output buffer
}</pre>

<p>Promise-based version:</p>

<pre class="brush: js">offlineAudioCtx.startRendering().then(function(buffer) {
  // buffer contains the output buffer
});
</pre>

<h3 id="Parameters">Parameters</h3>

<p>None.</p>

<h3 id="Returns">Returns</h3>

<p>Void.</p>

<h2 id="Example">Example</h2>

<p>In this simple example, we declare both an {{domxref("AudioContext")}} and an
  <code>OfflineAudioContext</code> object. We use the <code>AudioContext</code> to load an
  audio track via XHR ({{domxref("BaseAudioContext.decodeAudioData")}}), then the
  <code>OfflineAudioContext</code> to render the audio into an
  {{domxref("AudioBufferSourceNode")}} and play the track through. After the offline audio
  graph is set up, you need to render it to an {{domxref("AudioBuffer")}} using
  {{domxref("OfflineAudioContext.startRendering")}}.</p>

<p>When the <code>startRendering()</code> promise resolves, rendering has completed and
  the output <code>AudioBuffer</code> is returned out of the promise.</p>

<p>At this point we create another audio context, create an
  {{domxref("AudioBufferSourceNode")}} inside it, and set its buffer to be equal to the
  promise <code>AudioBuffer</code>. This is then played as part of a simple standard audio
  graph.</p>

<div class="note">
  <p><strong>Note</strong>: For a working example, see our <a
      href="https://mdn.github.io/webaudio-examples/offline-audio-context-promise/">offline-audio-context-promise</a>
    Github repo (see the <a href="https://github.com/mdn/webaudio-examples">source
      code</a> too.)</p>
</div>

<pre class="brush: js">// define online and offline audio context

var audioCtx = new AudioContext();
var offlineCtx = new OfflineAudioContext(2,44100*40,44100);

source = offlineCtx.createBufferSource();

// use XHR to load an audio track, and
// decodeAudioData to decode it and OfflineAudioContext to render it

function getData() {
  request = new XMLHttpRequest();

  request.open('GET', 'viper.ogg', true);

  request.responseType = 'arraybuffer';

  request.onload = function() {
    var audioData = request.response;

    audioCtx.decodeAudioData(audioData, function(buffer) {
      myBuffer = buffer;
      source.buffer = myBuffer;
      source.connect(offlineCtx.destination);
      source.start();
      //source.loop = true;
      offlineCtx.startRendering().then(function(renderedBuffer) {
        console.log('Rendering completed successfully');
        var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        var song = audioCtx.createBufferSource();
        song.buffer = renderedBuffer;

        song.connect(audioCtx.destination);

        play.onclick = function() {
          song.start();
        }
      }).catch(function(err) {
          console.log('Rendering failed: ' + err);
          // Note: The promise should reject when startRendering is called a second time on an OfflineAudioContext
      });
    });
  }

  request.send();
}

// Run getData to start the process off

getData();</pre>

<h2 id="Specifications">Specifications</h2>

{{Specifications}}

<h2 id="Browser_compatibility">Browser compatibility</h2>

<p>{{Compat}}</p>

<h2 id="See_also">See also</h2>

<ul>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a>
  </li>
</ul>
